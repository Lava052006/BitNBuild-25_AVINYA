{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b26845b-9840-4402-911c-514ed5060889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "print(\"All libraries imported successfully.\")\n",
    "\n",
    "# Check if a GPU is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707e123d-2c05-4888-a677-c2d47a21fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# 1. List all your manually graded CSV files\n",
    "FILE_PATHS = [\n",
    "    'ball_test.csv', \n",
    "    'bracelet_test.csv', \n",
    "    'lens_test.csv', \n",
    "    'fan_test.csv', \n",
    "    'coffee_test.csv', \n",
    "    'ps4_controller_test.csv'\n",
    "]\n",
    "\n",
    "# 2. Choose the base model to fine-tune. RoBERTa is our best performer so far.\n",
    "BASE_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# 3. Define the name for your new, custom model\n",
    "NEW_MODEL_NAME = \"review-sentiment-roberta-custom\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b3f60de-c3b7-46f3-8ec6-985ae8692434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared. Total examples: 374\n",
      "\n",
      "Label Distribution:\n",
      "label\n",
      "0    302\n",
      "2     52\n",
      "1     20\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usefull for overloading the hand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good product</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  label\n",
       "0                              good      0\n",
       "1                              good      0\n",
       "2  usefull for overloading the hand      0\n",
       "3                      good product      0\n",
       "4                              good      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Cell 4: Load and Prepare the Dataset\n",
    "# --- Step 1: Load, Combine, and Preprocess Data ---\n",
    "\n",
    "# Load all CSVs into a single DataFrame\n",
    "list_of_dfs = [pd.read_csv(fp) for fp in FILE_PATHS]\n",
    "df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "# Use the same text cleaning function from our analysis notebook\n",
    "def clean_review_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.replace('READ MORE', '')\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['text'] = df['review_text'].apply(clean_review_text)\n",
    "\n",
    "# Handle labels: Replace 'F' with 'N' and create integer labels\n",
    "df['label_str'] = df['review_feel'].replace('F', 'N')\n",
    "\n",
    "# Define our label mapping\n",
    "labels = ['positive', 'neutral', 'negative']\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "# Map string labels ('P', 'O', 'N') to our new integer labels\n",
    "str_to_id_map = {'P': label2id['positive'], 'O': label2id['neutral'], 'N': label2id['negative']}\n",
    "df['label'] = df['label_str'].map(str_to_id_map)\n",
    "\n",
    "# Remove rows with missing labels or text\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Keep only the columns we need\n",
    "final_df = df[['text', 'label']]\n",
    "\n",
    "print(f\"Dataset prepared. Total examples: {len(final_df)}\")\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(final_df['label'].value_counts())\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab9e1605-6dd4-4d8c-b94f-da16d1dcbc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 336\n",
      "Evaluation set size: 38\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Split Data into Training and Validation Sets ---\n",
    "\n",
    "# Split the DataFrame (e.g., 90% for training, 10% for validation)\n",
    "train_df, eval_df = train_test_split(final_df, test_size=0.1, random_state=42, stratify=final_df['label'])\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Evaluation set size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaf9a528-bde4-41e2-b6f3-9edf854fb058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                                            | 0/336 [00:00<?, ? examples/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|███████████████████████████████████████████████| 336/336 [00:00<00:00, 15863.37 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████| 38/38 [00:00<00:00, 7206.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Tokenize the Datasets ---\n",
    "\n",
    "# Load the tokenizer for our base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "# Create a function to tokenize the text\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply the tokenization to our datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Tokenization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d3935b4-0135-4b3e-a0a2-52839fccedae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model loaded and metrics function defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Load Model and Define Metrics ---\n",
    "\n",
    "# Load the pre-trained model, configured for our 3 labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL, \n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device) # Move model to GPU if available\n",
    "\n",
    "# Define the function to compute metrics during evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"macro\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1_macro\": f1}\n",
    "\n",
    "print(\"Base model loaded and metrics function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "892b961a-0e90-4282-9402-bfc06dd30aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arguments set successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Define Training Arguments (FINAL, SIMPLIFIED VERSION) ---\n",
    "\n",
    "# We will evaluate and save at the end of each epoch.\n",
    "# Training set size = 436, batch_size = 8 -> Steps per epoch = 55.\n",
    "EVAL_AND_SAVE_STEPS = 55 \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=NEW_MODEL_NAME,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    \n",
    "    # --- Correct arguments for your library version ---\n",
    "    do_eval=True,                      # Enable evaluation\n",
    "    eval_steps=EVAL_AND_SAVE_STEPS,    # Evaluate every 55 steps\n",
    "    save_steps=EVAL_AND_SAVE_STEPS,    # Save every 55 steps\n",
    "    \n",
    "    # We are removing `load_best_model_at_end` to work around a version-specific bug.\n",
    "    # The trainer will still save and evaluate every 55 steps.\n",
    ")\n",
    "\n",
    "print(\"Training arguments set successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6e5152a-e544-4058-a22c-4f2ecb523e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the fine-tuning process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\review-radar-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 04:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.796700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.280500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.290800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\review-radar-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Create and Run the Trainer (FINAL CORRECTED VERSION) ---\n",
    "\n",
    "from transformers import DataCollatorWithPadding # <-- 1. IMPORT THE HELPER\n",
    "\n",
    "# Instantiate the data collator, which will handle padding for each batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator, # <-- 2. TELL THE TRAINER TO USE IT\n",
    ")\n",
    "\n",
    "print(\"Starting the fine-tuning process...\")\n",
    "trainer.train()\n",
    "print(\"Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e0556d-ebbb-4693-a0cd-0cd06ff1e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading your custom fine-tuned model from 'review-sentiment-roberta-custom/checkpoint-165'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully. Running test predictions...\n",
      "\n",
      "Review: 'The product stopped working after one day, very disappointing.'\n",
      "Predicted Sentiment: negative (Score: 0.9935)\n",
      "\n",
      "Review: 'It works exactly as described, I'm very happy with this purchase.'\n",
      "Predicted Sentiment: positive (Score: 0.9975)\n",
      "\n",
      "Review: 'The delivery was on time.'\n",
      "Predicted Sentiment: positive (Score: 0.8855)\n",
      "\n",
      "Review: 'this is the worst thing i have ever bought'\n",
      "Predicted Sentiment: negative (Score: 0.9908)\n",
      "\n",
      "Review: 'it is okay, not great but not bad either'\n",
      "Predicted Sentiment: neutral (Score: 0.6627)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: Test Your Fine-Tuned Model (Corrected Path) ---\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# The path must point to the specific checkpoint with the saved model files.\n",
    "# This should be the last checkpoint saved during training.\n",
    "MODEL_CHECKPOINT_PATH = \"review-sentiment-roberta-custom/checkpoint-165\" \n",
    "\n",
    "print(f\"Loading your custom fine-tuned model from '{MODEL_CHECKPOINT_PATH}'...\")\n",
    "\n",
    "my_custom_pipeline = pipeline(\n",
    "    \"sentiment-analysis\", \n",
    "    model=MODEL_CHECKPOINT_PATH, # <-- This now points to the correct sub-folder\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully. Running test predictions...\")\n",
    "\n",
    "reviews = [\n",
    "    \"The product stopped working after one day, very disappointing.\",\n",
    "    \"It works exactly as described, I'm very happy with this purchase.\",\n",
    "    \"The delivery was on time.\",\n",
    "    \"this is the worst thing i have ever bought\",\n",
    "    \"it is okay, not great but not bad either\"\n",
    "]\n",
    "\n",
    "results = my_custom_pipeline(reviews)\n",
    "\n",
    "for review, result in zip(reviews, results):\n",
    "    print(f\"\\nReview: '{review}'\")\n",
    "    print(f\"Predicted Sentiment: {result['label']} (Score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1818f70-d970-4e4a-bd3c-9ac7d44dd1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
